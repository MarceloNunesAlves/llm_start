{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e5b2dc9-48e3-4202-a56d-2529376b75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_groq\n",
    "#!pip install pandas\n",
    "#!pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a49425b6-a680-4413-a432-87d5c2e4b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"[token]\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-teste-lang-grapth\"\n",
    "\n",
    "llm = ChatGroq(temperature=0, groq_api_key=\"[token]\", model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "989545cd-03fd-43de-b340-8d025cdf0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import operator\n",
    "from functools import partial\n",
    "from typing import Annotated, List, Literal, Optional, Sequence, TypedDict\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db6d8828-d376-4d4e-9114-65c341f08899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "maria_uri = 'mysql+mysqlconnector://root:art_llama3@localhost:3306/mme'\n",
    "db = SQLDatabase.from_uri(maria_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65ec19e3-d661-4cd0-9411-0d0c0b489e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23a47e11-d724-4801-ae17-8246ed047b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawToolMessage(ToolMessage):\n",
    "    \"\"\"\n",
    "    Customized Tool message that lets us pass around the raw tool outputs (along with string contents for passing back to the model).\n",
    "    \"\"\"\n",
    "\n",
    "    raw: dict\n",
    "    \"\"\"Arbitrary (non-string) tool outputs. Won't be sent to model.\"\"\"\n",
    "    tool_name: str\n",
    "    \"\"\"Name of tool that generated output.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "862ecc0d-da98-4ff7-899f-99b15a54df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool schema for querying SQL db\n",
    "class create_df_from_sql(BaseModel):\n",
    "    \"\"\"Execute a PostgreSQL SELECT statement and use the results to create a DataFrame with the given column names.\"\"\"\n",
    "\n",
    "    select_query: str = Field(..., description=\"A PostgreSQL SELECT statement.\")\n",
    "    # We're going to convert the results to a Pandas DataFrame that we pass\n",
    "    # to the code intepreter, so we also have the model generate useful column and\n",
    "    # variable names for this DataFrame that the model will refer to when writing\n",
    "    # python code.\n",
    "    df_columns: List[str] = Field(\n",
    "        ..., description=\"Ordered names to give the DataFrame columns.\"\n",
    "    )\n",
    "    df_name: str = Field(\n",
    "        ..., description=\"The name to give the DataFrame variable in downstream code.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Tool schema for writing Python code\n",
    "class python_shell(BaseModel):\n",
    "    \"\"\"Execute Python code that analyzes the DataFrames that have been generated. Make sure to print any important results.\"\"\"\n",
    "\n",
    "    code: str = Field(\n",
    "        ...,\n",
    "        description=\"The code to execute. Make sure to print any important results.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de52588e-8351-43c9-8012-5f55aaa154be",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\\\n",
    "You are an expert at MariaDB and Python. You have access to a MariaDB database \\\n",
    "with the following tables\n",
    "\n",
    "{db.table_info}\n",
    "\n",
    "Given a user question related to the data in the database, \\\n",
    "first get the relevant data from the table as a DataFrame using the create_df_from_sql tool. Then use the \\\n",
    "python_shell to do any analysis required to answer the user question.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def call_model(state: AgentState) -> dict:\n",
    "    \"\"\"Call model with tools passed in.\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    chain = prompt | llm.bind_tools([create_df_from_sql, python_shell])\n",
    "    messages.append(chain.invoke({\"messages\": state[\"messages\"]}))\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4469a0ac-8d8d-40b2-a20b-47ce38eed934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_query(state: AgentState) -> dict:\n",
    "    \"\"\"Execute the latest SQL queries.\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        if tool_call[\"name\"] != \"create_df_from_sql\":\n",
    "            continue\n",
    "\n",
    "        # Execute SQL query\n",
    "        res = db.run(tool_call[\"args\"][\"select_query\"], fetch=\"cursor\").fetchall()\n",
    "\n",
    "        # Convert result to Pandas DataFrame\n",
    "        df_columns = tool_call[\"args\"][\"df_columns\"]\n",
    "        df = pd.DataFrame(res, columns=df_columns)\n",
    "        df_name = tool_call[\"args\"][\"df_name\"]\n",
    "\n",
    "        # Add tool output message\n",
    "        messages.append(\n",
    "            RawToolMessage(\n",
    "                f\"Generated dataframe {df_name} with columns {df_columns}\",  # What's sent to model.\n",
    "                raw={df_name: df},\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "                tool_name=tool_call[\"name\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ea18db9-e6c6-4cd0-a947-dc544d9026de",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl_tool = PythonREPLTool()\n",
    "tools = [python_repl_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3d87a3b-c512-482c-8785-d2684f7c0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upload_dfs_to_repl(state: dict) -> str:\n",
    "    \"\"\"\n",
    "    Save generated dfs locally and return code for loading them.\n",
    "    \"\"\"\n",
    "    df_dicts = [\n",
    "        msg['raw']\n",
    "        for msg in state[\"messages\"]\n",
    "        if isinstance(msg, RawToolMessage) and msg['tool_name'] == \"create_df_from_sql\"\n",
    "    ]\n",
    "    name_df_map = {name: pd.DataFrame(df) for df_dict in df_dicts for name, df in df_dict.items()}\n",
    "\n",
    "    # Save DataFrames as CSV files locally\n",
    "    for name, df in name_df_map.items():\n",
    "        df.to_csv(f\"{name}.csv\", index=False)\n",
    "\n",
    "    # Code for loading the saved files\n",
    "    df_code = \"import pandas as pd\\n\" + \"\\n\".join(\n",
    "        f\"{name} = pd.read_csv('{name}.csv')\" for name in name_df_map\n",
    "    )\n",
    "    return df_code\n",
    "\n",
    "def _repl_result_to_msg_content(repl_result: dict) -> str:\n",
    "    \"\"\"\n",
    "    Display images with including them in tool message content.\n",
    "    \"\"\"\n",
    "    content = {}\n",
    "    for k, v in repl_result.items():\n",
    "        # Any image results are returned as a dict of the form:\n",
    "        # {\"type\": \"image\", \"base64_data\": \"...\"}\n",
    "        if isinstance(repl_result[k], dict) and repl_result[k][\"type\"] == \"image\":\n",
    "            # Decode and display image\n",
    "            base64_str = repl_result[k][\"base64_data\"]\n",
    "            img = Image.open(io.BytesIO(base64.decodebytes(bytes(base64_str, \"utf-8\"))))\n",
    "            display(img)\n",
    "        else:\n",
    "            content[k] = repl_result[k]\n",
    "    return json.dumps(content, indent=2)\n",
    "\n",
    "\n",
    "def execute_python(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Execute the latest generated Python code.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    df_code = _upload_dfs_to_repl(state)\n",
    "    last_ai_msg = [msg for msg in state[\"messages\"] if isinstance(msg, AIMessage)][-1]\n",
    "    for tool_call in last_ai_msg.tool_calls:\n",
    "        if tool_call[\"name\"] != \"python_shell\":\n",
    "            continue\n",
    "\n",
    "        generated_code = tool_call[\"args\"][\"code\"]\n",
    "        repl_result = repl.execute(df_code + \"\\n\" + generated_code)\n",
    "\n",
    "        messages.append(\n",
    "            RawToolMessage(\n",
    "                _repl_result_to_msg_content(repl_result),\n",
    "                raw=repl_result,\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "                tool_name=tool_call[\"name\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19907f28-1956-482f-a8bd-c4cdaf27de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    If any Tool messages were generated in the last cycle that means we need to call the model again to interpret the latest results.\n",
    "    \"\"\"\n",
    "    return \"execute_sql_query\" if state[\"messages\"][-1].tool_calls else END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fa024f2-0079-4fe2-b1ba-4c558e62a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"call_model\", call_model)\n",
    "workflow.add_node(\"execute_sql_query\", execute_sql_query)\n",
    "workflow.add_node(\"execute_python\", execute_python)\n",
    "\n",
    "workflow.set_entry_point(\"call_model\")\n",
    "workflow.add_edge(\"execute_sql_query\", \"execute_python\")\n",
    "workflow.add_edge(\"execute_python\", \"call_model\")\n",
    "workflow.add_conditional_edges(\"call_model\", should_continue)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e05cf47e-657d-4a5b-85ff-b6b6532ea73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       +-----------+                                    \n",
      "                                       | __start__ |                                    \n",
      "                                       +-----------+                                    \n",
      "                                              *                                         \n",
      "                                              *                                         \n",
      "                                              *                                         \n",
      "                                       +------------+                                   \n",
      "                                    ...| call_model |***                                \n",
      "                             .......   +------------+   *******                         \n",
      "                     ........          ..           ...        *******                  \n",
      "              .......                ..                ...            ******            \n",
      "          ....                     ..                     ..                *******     \n",
      "+---------+           +-------------------+                 ..                     **** \n",
      "| __end__ |           | execute_sql_query |                  .                  ****    \n",
      "+---------+           +-------------------+*                 .              ****        \n",
      "                                            *****           .          *****            \n",
      "                                                 ****       .      ****                 \n",
      "                                                     ***    .   ***                     \n",
      "                                                  +----------------+                    \n",
      "                                                  | execute_python |                    \n",
      "                                                  +----------------+                    \n"
     ]
    }
   ],
   "source": [
    "print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b88c76f0-90ac-4b3b-8ab8-926269bb074e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RawToolMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQual foi o top 4 estados que tiveram o maior consumo em MWh total? Gere um gráfico de barras com o estado e o total MWh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1691\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1690\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1691\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1693\u001b[0m     config,\n\u001b[1;32m   1694\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1695\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1696\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[1;32m   1697\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1698\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1699\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1701\u001b[0m ):\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1703\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1110\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1780\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1778\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1779\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/site-packages/langgraph/pregel/retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/site-packages/langchain_core/runnables/base.py:2822\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2818\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2819\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2820\u001b[0m )\n\u001b[1;32m   2821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2822\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2824\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_tests/lib/python3.10/site-packages/langgraph/utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[39], line 46\u001b[0m, in \u001b[0;36mexecute_python\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mExecute the latest generated Python code.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m messages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 46\u001b[0m df_code \u001b[38;5;241m=\u001b[39m \u001b[43m_upload_dfs_to_repl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m last_ai_msg \u001b[38;5;241m=\u001b[39m [msg \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, AIMessage)][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m last_ai_msg\u001b[38;5;241m.\u001b[39mtool_calls:\n",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m, in \u001b[0;36m_upload_dfs_to_repl\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_upload_dfs_to_repl\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Save generated dfs locally and return code for loading them.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     df_dicts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         msg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, RawToolMessage) \u001b[38;5;129;01mand\u001b[39;00m msg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtool_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_df_from_sql\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m     name_df_map \u001b[38;5;241m=\u001b[39m {name: pd\u001b[38;5;241m.\u001b[39mDataFrame(df) \u001b[38;5;28;01mfor\u001b[39;00m df_dict \u001b[38;5;129;01min\u001b[39;00m df_dicts \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m df_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Save DataFrames as CSV files locally\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_upload_dfs_to_repl\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Save generated dfs locally and return code for loading them.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     df_dicts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         msg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, RawToolMessage) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtool_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_df_from_sql\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m     name_df_map \u001b[38;5;241m=\u001b[39m {name: pd\u001b[38;5;241m.\u001b[39mDataFrame(df) \u001b[38;5;28;01mfor\u001b[39;00m df_dict \u001b[38;5;129;01min\u001b[39;00m df_dicts \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m df_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Save DataFrames as CSV files locally\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RawToolMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "output = app.invoke({\"messages\": [(\"human\", \"Qual foi o top 4 estados que tiveram o maior consumo em MWh total? Gere um gráfico de barras com o estado e o total MWh\")]})\n",
    "print(output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66533c33-2c6e-47dd-ada8-4324a97565bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
