from langchain_experimental.tools import PythonREPLTool
from langchain_community.agent_toolkits import create_sql_agent
from langchain_groq import ChatGroq
from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from langchain_community.utilities import SQLDatabase
from langchain_community.llms import Ollama

from typing import Annotated, Sequence, TypedDict

import re
import os
import operator
import functools


os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_API_KEY"] = "[token]"
os.environ["LANGCHAIN_PROJECT"] = "pr-teste-lang-grapth"

llm = ChatGroq(temperature=0, groq_api_key="[token]", model_name="llama3-70b-8192")
llm_code = Ollama(model="llama3")


# defining the AgentState that holds messages and where to go next
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    # The 'next' field indicates where to route to next
    next: str


def agent_node(state, llm, name):
    messages = state['messages']
    result = llm.invoke("based on the data returned from the user's request database, "
                        "generate a code in python that creates a graph in matplotlib "
                        "and stores the graph image in base64 variable name: base64_graph."
                        " Response just code.\n{}".format(messages[-1]))

    pattern = re.compile(r'```(.*?)```', re.DOTALL)
    python_code = pattern.findall(result.content)
    if len(python_code) > 0:
        running_content = {}
        code_running = python_code[0].replace('python', '').replace('Python', '')
        exec(code_running, running_content)
        print(f"imagem aqui: {running_content['base64_graph']}")
        state['messages'].append(f"Chat generate for user: {running_content['base64_graph']}")
    return state

class SQLHandler(BaseCallbackHandler):
    def __init__(self):
        self.sql_result = []

    def on_agent_action(self, action, **kwargs):
        """Run on agent action. if the tool being used is sql_db_query,
         it means we're submitting the sql and we can
         record it as the final sql"""

        if action.tool in ["sql_db_query"]:
            self.sql_result.append(action.tool_input)

def agent_sql_node(state, agent, name):
    handler = SQLHandler()
    result = agent.invoke({'input': state["messages"][-1].content}, {'callbacks': [handler]})
    if len(handler.sql_result) > 0:
        sql_query = handler.sql_result[0]['query']
        return {"messages": [SystemMessage(content="This is the return data from the database: " +
                                          db.run(sql_query, fetch="all", include_columns=True), name=name)]}


 maria_uri = 'mysql+mysqlconnector://root:art_llama3@localhost:3306/mme'
db = SQLDatabase.from_uri(maria_uri)

# QueryBuild as a node
sql_agent = create_sql_agent(llm, db=db, agent_type="tool-calling", max_iterations=5, verbose=True)
sql_node = functools.partial(agent_sql_node, agent=sql_agent, name="QueryBuild")

# Coder as a node
code_node = functools.partial(agent_node, llm=llm, name="Coder")

# defining the StateGraph
workflow = StateGraph(AgentState)

# agents as a node, supervisor_chain as a node
workflow.add_node("QueryBuild", sql_node)
workflow.add_node("Coder", code_node)

# when agents are done with the task, next one should be supervisor ALWAYS
workflow.add_edge("QueryBuild", "Coder")

# starting point should be QueryBuild
workflow.set_entry_point("QueryBuild")
workflow.set_finish_point("Coder")

graph = workflow.compile()

final_state = graph.invoke(
    {"messages": [HumanMessage(content="Qual foi o top 4 estados que tiveram o maior consumo em MWh total? Gere um gr√°fico de barras com o estado e o total MWh")]}
)



